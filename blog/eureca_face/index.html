<!doctype html> <html lang=en> <head> <meta charset=utf-8> <meta content="width=device-width,initial-scale=1" name=viewport> <meta content=#333333 name=theme-color> <base href=/ > <link href=global.css rel=stylesheet> <link href=manifest.json rel=manifest crossorigin=use-credentials> <link href=logo.png rel=icon type=image/png> <script> MathJax = {
			tex: {
				inlineMath: [['$', '$'], ['\\(', '\\)']],
				processEscapes: true
			},
			svg: {
				fontCache: 'global'
			}
		}; </script> <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?version=4.8.0&features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js async id=MathJax-script></script> <script src=https://kit.fontawesome.com/d1e7542e7f.js crossorigin=anonymous></script> <link href=client/main.677622768.css rel=stylesheet><link href=client/[slug].d2f2c26c.css rel=stylesheet><link href=client/client.4da8ec3a.css rel=stylesheet> <noscript id=sapper-head-start></noscript><title>Effects of Degradation on Face Detectors</title><noscript id=sapper-head-end></noscript> </head> <body> <div id=sapper> <nav class=svelte-wyfi55><ul class=svelte-wyfi55><li class=svelte-wyfi55><a href=blog rel=prefetch aria-current=page class="svelte-wyfi55 btn-gen">Blog</a></li> <li class=svelte-wyfi55><a href=. class="svelte-wyfi55 btn-gen">Home</a></li> </ul></nav> <main class=svelte-1xjjggr> <div class="content svelte-1d9fknd"><h1>Effects of Degradation on Face Detectors</h1> <hr> <p>This project was done to complete one of my breadth requirements for the Tickle Engineering Honors program. The contents of the project were presented at the 2021 EUReCA Symposium as a <a href=https://github.com/vjsrinivas/eureca_face/blob/master/post.pdf rel=nofollow target=_blank>poster</a>. To keep proper context, the project was completed within <strong>less than a month</strong> and is a continuation of adjacent, prior works regarding image degradation and Convolutional Neural Networks.</p> <h2 id=table-of-contents>Table of Contents</h2> <ul> <li><a href=javascript:; onclick="document.location.hash='Description';">Description</a></li> <li><a href=javascript:; onclick="document.location.hash='Abstract';">Abstract</a></li> <li><a href=javascript:; onclick="document.location.hash='face-detectors';">Face Detectors</a></li> <li><a href=javascript:; onclick="document.location.hash='Degradation';">Degradation</a></li> <li><a href=javascript:; onclick="document.location.hash='Recovery';">Recovery</a></li> <li><a href=javascript:; onclick="document.location.hash='Results';">Results</a></li> <li><a href=javascript:; onclick="document.location.hash='running-code';">Running Code</a></li> </ul> <figure> <video autoplay loop muted> <source alt="Video showing animation of an unaltered image, its detection, a degrade image, and a corrected image" src=post-res/eureca_face/anim_header_1.mp4 type=video/mp4> Your browser does not support the video tag. </video> </figure> <h2 id=abstract>Abstract</h2> <p>With the popularization of object detection via convolutional neural networks (CNN), major work has been done with specialized detection tasks, such as using CNNs for facial recognition and detection. Additionally, CNNs have now been deployed in practical settings, where the networks must work with sub-par equipment and operate in non-ideal environments.</p> <p>In this research project, we look into some of the standard image-based obstacles faced by state-of-the-art face detectors in the real world, such as degraded camera quality and transmission interruptions. With these obstacles, we experiment and quantitatively describe how the CNNs react in these scenarios.</p> <p>Additionally, we reconstruct the “degraded” image with various image processing methods in order to recover detection accuracy. Furthermore, we quantitatively establish connections between certain recovery methods, their intensity, as well as the intensity of the degradation with the ability to recover the detection accuracy.</p> <h2 id=face-detectors>Face Detectors:</h2> <figure> <img alt="Example of detection with RetinaFace from the RetinaFace authors" src=post-res/eureca_face/11513D05.jpg> </figure> <ul> <li><p>TinaFace (part of VedaDetector)</p> <ul> <li><strong>Description:</strong> TinaFace is the SoTA (as of this writing) in terms of realtime face detection on the WIDERFACE testset. The model utilizes recent advancements in general object detection and frames the face detection task as a "small-object" detection task. </li> </ul> </li> <li><p>RetinaFace</p> <ul> <li><strong>Description:</strong> RetinaFace is a realtime face detector that was released in late-2019. It utilizes information summarized from a <strong>multi-task objective loss function</strong> in order to improve "small-face" detection. This object detector also was able to produce facial landmarks, and the authors themselves labeled the landmarks within the <code>train</code> and <code>validation</code> sets of WIDERFACE. The landmarks were also used in the multi-task objective loss function.</li> </ul> </li> <li><p>DSFD (Dual-Shot Face Detector)</p> <ul> <li><p><strong>Description:</strong> DSFD was a model created by the Tencent Research Group and features a "Feature Enhancement Module", where feature maps are taken through a portion of the network as the "first shot". While going through each stage of the "first shot", the "Feature Enhancement Module" produces a "second shot". Together, they produce a network that can accurately detect small faces within dense crowds.</p> </li> <li><p><strong>Note:</strong> The DSFD used in this project was a optimized version, which was ~9% off the original DSFD WIDERFACE validation score (81% vs 89% on the hard-set). The DSFD network utilizes "better feature learning, progressive loss design, and anchor assign based data augmentation."</p> </li> </ul> </li> </ul> <h3 id=degradation>Degradation</h3> <figure> <img alt="Diagram showing the effects of each degradation" src=post-res/eureca_face/noise_matrix.png width=800> </figure> <ul> <li><p><strong>Gaussian Noise</strong></p> <ul> <li><strong>Description:</strong> Commonly occurs in digital photography. For this project, the Gaussian Distribution was varied by adjusting the standard deviation. By adjusting standard deviation, the noise matrix values become higher in the [0-255] color scale. This in turn increases the visibility of noise on the image.</li> </ul> </li> <li><p><strong>Salt & Pepper</strong></p> <ul> <li><strong>Description:</strong> This type of noise occurs in sharp pulses during image transmission. The variable for this noise is the percentage of the image "covered" with a white or black pixel. The ratio of white to black pixels within the noise distribution is fixed.</li> </ul> </li> <li><p><strong>Poisson</strong></p> <ul> <li><strong>Description:</strong> This noise occurs within CT & X-Ray scans as a result of stray radiation bombardment. The noise distribution is controlled by the lambda parameter.</li> </ul> </li> <li><p><strong>Gamma</strong></p> <ul> <li><strong>Description:</strong> This noise is similar to Poisson, but the noise distribution is varied by "gamma shape", and as the gamma shape increases, the image becomes more "white-washed". This is similar to increasing uniform gamma factor, where a higher gamma factor increases the brightness.</li> </ul> </li> </ul> <h3 id=recovery>Recovery</h3> <figure> <img alt="Example of recovery methods" src=post-res/eureca_face/median_demo.png width=800> </figure> <ul> <li><p><strong>Median Filter:</strong></p> <ul> <li><strong>Description:</strong> Use a <code>nxn</code> kernel (where <code>n</code> is a non-zero integer) and slides through image. While sliding, it takes the median value of the pixel values within the kernel and assigns that value to those pixels. This method "smoothens" the image out, and the larger the kernel size, the smoother the image.</li> </ul> </li> <li><p><strong>Histogram Equalization:</strong></p> <ul> <li><strong>Description:</strong> Plot the frequency of each pixel value (with a histogram) and equalizes those frequencies. This histogram plotting and equalization occurs channel-by-channel basis. In terms of channels, the histogram equalization is applied in the YCbCR color space(Luminance, Chroma Blue, Chroma Red).</li> </ul> </li> </ul> <p><strong>Note:</strong> Both correction methods can have an optimized runtime of &lt;10-20ms, which makes them suitable for real-time corrections.</p> <h2 id=results>Results</h2> <p>The following are graphs showing the decreasing shape of mAP as a given noise's intensity rises.</p> <h3 id=gaussian-blur>Gaussian Blur</h3> <figure> <img alt="mAP Graph of Gaussian Blur on all models" src=post-res/eureca_face/overview_gaussian_noise_graph.png width=800> </figure> <h3 id=salt--pepper>Salt & Pepper</h3> <figure> <img alt="mAP Graph of Salt & Pepper on all models" src=post-res/eureca_face/overview_salt_pepper_graph.png width=800> </figure> <h3 id=poisson>Poisson</h3> <figure> <img alt="mAP Graph of Poisson on all models" src=post-res/eureca_face/overview_poisson_graph.png width=800> </figure> <h3 id=gamma>Gamma</h3> <figure> <img alt="mAP Graph of Gamma on all models" src=post-res/eureca_face/overview_gamma_graph.png width=800> </figure> <p>The following are graphs representing the trend of recovery for each noise intensity of a given noise at a certain level of a correction. Median filter was applied to Salt & Pepper, Gaussian Blur, and Poisson while Histogram Equalization was applied to Gamma alone.</p> <h3 id=retinaface>Retinaface</h3> <figure> <img alt="Graph showing correction improvements of gaussian noise with median filter" src=post-res/eureca_face/overview_median_gaussian_noise_retinaface.png width=800> </figure> <figure> <img alt="Graph showing correction improvements of poisson noise with median filter" src=post-res/eureca_face/overview_median_poisson_retinaface.png width=800> </figure> <figure> <img alt="Graph showing correction improvements of salt & pepper with median filter" src=post-res/eureca_face/overview_median_salt_pepper_retinaface.png width=800> </figure> <figure> <img alt="Graph showing correction improvements of gamma with histogram equalization" src=post-res/eureca_face/overview_he_gamma_retinaface.png width=800> </figure> <h3 id=dsfd>DSFD</h3> <figure> <img alt="Graph showing correction improvements of gaussian noise with median filter" src=post-res/eureca_face/overview_median_gaussian_noise_dsfd.png width=800> </figure> <figure> <img alt="Graph showing correction improvements of poisson noise with median filter" src=post-res/eureca_face/overview_median_poisson_dsfd.png width=800> </figure> <figure> <img alt="Graph showing correction improvements of salt & pepper with median filter" src=post-res/eureca_face/overview_median_salt_pepper_dsfd.png width=800> </figure> <figure> <img alt="Graph showing correction improvements of gamma with histogram equalization" src=post-res/eureca_face/overview_he_gamma_dsfd.png width=800> </figure> <h3 id=tinaface>Tinaface</h3> <p><code>Incomplete</code></p> <h2 id=conclusions>Conclusions</h2> <p>This project shows the degradation behavior that noises such as Gaussian Blur and Salt & Pepper have on highly-accurate face detectors. Salt & Pepper had an accuracy decrease "shape" resembling an inverted S-curve. I believe this is mainly due to the fact that sharp pixel-wise color changes, such as completely black or white, can have drastic effects on the feature extraction from the first set of convolution layers, which can have a cascading effect later on in the network.</p> <p>For a similar reason, this is why you see tamer accuracy decrease "shapes" for Poisson and Gamma (although the later half of Gamma had a drastic decrease -- this is because at a certain point the white-washing had removed enough features to the point where the image is basically white to us).</p> <p>Gaussian noise had a neutral accuracy decrease "shape". I believe the reason for this is because the noise is colored and the distribution of colors at most noise levels are not large enough to drastically affect the original pixel color. Only at higher noise intensities do the values become significant enough for the original color values to significantly shift from their original "domain" of color. With this significant shift, an object's features will be unrecognizable. </p> <figure> <img alt="Example of median filter recovering detections from a image at a higher salt & pepper intensity" src=post-res/eureca_face/median_fix_demo.png width=800> </figure> <figure> <img alt="Example of histogram equalization recovering a moderate amount of faces from a very white-washed image" src=post-res/eureca_face/he_fix_demo.png width=800> </figure> <p><strong>The source code and documentation on how to set up this project is located <a href=https://github.com/vjsrinivas/eureca_face rel=nofollow target=_blank>here</a></strong></p> </div></main></div> <script>__SAPPER__={baseUrl:"",preloaded:[void 0,null,(function(a){return {post:{title:"Effects of Degradation on Face Detectors",description:"This project was done to complete one of my breadth requirements for the Tickle Engineering Honors program. The contents of the project were presented at the 2021 EUReCA Symposium as a poster. To keep proper context, the project was completed within less than a month and is a continuation of adjacent, prior works regarding image degradation and Convolutional Neural Networks.",slug:"eureca_face",html:"\u003Cp\u003EThis project was done to complete one of my breadth requirements for the Tickle Engineering Honors program. The contents of the project were presented at the 2021 EUReCA Symposium as a \u003Ca target=\"_blank\" rel=\"nofollow\" href=\"https:\u002F\u002Fgithub.com\u002Fvjsrinivas\u002Feureca_face\u002Fblob\u002Fmaster\u002Fpost.pdf\"\u003Eposter\u003C\u002Fa\u003E. To keep proper context, the project was completed within \u003Cstrong\u003Eless than a month\u003C\u002Fstrong\u003E and is a continuation of adjacent, prior works regarding image degradation and Convolutional Neural Networks.\u003C\u002Fp\u003E\n\u003Ch2 id=\"table-of-contents\"\u003ETable of Contents\u003C\u002Fh2\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Ca onclick=\"document.location.hash='Description';\" href=\"javascript:;\"\u003EDescription\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Ca onclick=\"document.location.hash='Abstract';\" href=\"javascript:;\"\u003EAbstract\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Ca onclick=\"document.location.hash='face-detectors';\" href=\"javascript:;\"\u003EFace Detectors\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Ca onclick=\"document.location.hash='Degradation';\" href=\"javascript:;\"\u003EDegradation\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Ca onclick=\"document.location.hash='Recovery';\" href=\"javascript:;\"\u003ERecovery\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Ca onclick=\"document.location.hash='Results';\" href=\"javascript:;\"\u003EResults\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Ca onclick=\"document.location.hash='running-code';\" href=\"javascript:;\"\u003ERunning Code\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cfigure\u003E\n\n\u003Cvideo autoplay muted loop\u003E\n  \u003Csource src=\"post-res\u002Feureca_face\u002Fanim_header_1.mp4\" type=\"video\u002Fmp4\" alt=\"Video showing animation of an unaltered image, its detection, a degrade image, and a corrected image\"\u003E\n  Your browser does not support the video tag.\n\u003C\u002Fvideo\u003E\n\u003C\u002Ffigure\u003E\n\n\u003Ch2 id=\"abstract\"\u003EAbstract\u003C\u002Fh2\u003E\n\u003Cp\u003EWith the popularization of object detection via convolutional neural networks (CNN), major work has been done with specialized detection tasks, such as using CNNs for facial recognition and detection. Additionally, CNNs have now been deployed in practical settings, where the networks must work with sub-par equipment and operate in non-ideal environments.\u003C\u002Fp\u003E\n\u003Cp\u003EIn this research project, we look into some of the standard image-based obstacles faced by state-of-the-art face detectors in the real world, such as degraded camera quality and transmission interruptions. With these obstacles, we experiment and quantitatively describe how the CNNs react in these scenarios.\u003C\u002Fp\u003E\n\u003Cp\u003EAdditionally, we reconstruct the “degraded” image with various image processing methods in order to recover detection accuracy. Furthermore, we quantitatively establish connections between certain recovery methods, their intensity, as well as the intensity of the degradation with the ability to recover the detection accuracy.\u003C\u002Fp\u003E\n\u003Ch2 id=\"face-detectors\"\u003EFace Detectors:\u003C\u002Fh2\u003E\n\u003Cfigure\u003E\n\u003Cimg src=\"post-res\u002Feureca_face\u002F11513D05.jpg\" alt=\"Example of detection with RetinaFace from the RetinaFace authors\"\u002F\u003E\n\u003C\u002Ffigure\u003E\n\n\n\u003Cul\u003E\n\u003Cli\u003E\u003Cp\u003ETinaFace (part of VedaDetector)\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003EDescription:\u003C\u002Fstrong\u003E TinaFace is the SoTA (as of this writing) in terms of realtime face detection on the WIDERFACE testset. The model utilizes recent advancements in general object detection and frames the face detection task as a &quot;small-object&quot; detection task.  \u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Cp\u003ERetinaFace\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003EDescription:\u003C\u002Fstrong\u003E RetinaFace is a realtime face detector that was released in late-2019. It utilizes information summarized from a \u003Cstrong\u003Emulti-task objective loss function\u003C\u002Fstrong\u003E in order to improve &quot;small-face&quot; detection. This object detector also was able to produce facial landmarks, and the authors themselves labeled the landmarks within the \u003Ccode\u003Etrain\u003C\u002Fcode\u003E and \u003Ccode\u003Evalidation\u003C\u002Fcode\u003E sets of WIDERFACE. The landmarks were also used in the multi-task objective loss function.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Cp\u003EDSFD (Dual-Shot Face Detector)\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cp\u003E\u003Cstrong\u003EDescription:\u003C\u002Fstrong\u003E DSFD was a model created by the Tencent Research Group and features a &quot;Feature Enhancement Module&quot;, where feature maps are taken through a portion of the network as the &quot;first shot&quot;. While going through each stage of the &quot;first shot&quot;, the &quot;Feature Enhancement Module&quot; produces a &quot;second shot&quot;. Together, they produce a network that can accurately detect small faces within dense crowds.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Cp\u003E\u003Cstrong\u003ENote:\u003C\u002Fstrong\u003E The DSFD used in this project was a optimized version, which was ~9% off the original DSFD WIDERFACE validation score (81% vs 89% on the hard-set). The DSFD network utilizes &quot;better feature learning, progressive loss design, and anchor assign based data augmentation.&quot;\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch3 id=\"degradation\"\u003EDegradation\u003C\u002Fh3\u003E\n\u003Cfigure\u003E\n\u003Cimg src=\"post-res\u002Feureca_face\u002Fnoise_matrix.png\" width=\"800\" alt=\"Diagram showing the effects of each degradation\"\u002F\u003E\n\u003C\u002Ffigure\u003E\n\n\n\u003Cul\u003E\n\u003Cli\u003E\u003Cp\u003E\u003Cstrong\u003EGaussian Noise\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003EDescription:\u003C\u002Fstrong\u003E Commonly occurs in digital photography. For this project, the Gaussian Distribution was varied by adjusting the standard deviation. By adjusting standard deviation, the noise matrix values become higher in the [0-255] color scale. This in turn increases the visibility of noise on the image.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Cp\u003E\u003Cstrong\u003ESalt &amp; Pepper\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003EDescription:\u003C\u002Fstrong\u003E This type of noise occurs in sharp pulses during image transmission. The variable for this noise is the percentage of the image &quot;covered&quot; with a white or black pixel. The ratio of white to black pixels within the noise distribution is fixed.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Cp\u003E\u003Cstrong\u003EPoisson\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003EDescription:\u003C\u002Fstrong\u003E This noise occurs within CT &amp; X-Ray scans as a result of stray radiation bombardment. The noise distribution is controlled by the lambda parameter.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Cp\u003E\u003Cstrong\u003EGamma\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003EDescription:\u003C\u002Fstrong\u003E This noise is similar to Poisson, but the noise distribution is varied by &quot;gamma shape&quot;, and as the gamma shape increases, the image becomes more &quot;white-washed&quot;. This is similar to increasing uniform gamma factor, where a higher gamma factor increases the brightness.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch3 id=\"recovery\"\u003ERecovery\u003C\u002Fh3\u003E\n\u003Cfigure\u003E\n\u003Cimg src=\"post-res\u002Feureca_face\u002Fmedian_demo.png\" width=\"800\" alt=\"Example of recovery methods\"\u002F\u003E\n\u003C\u002Ffigure\u003E\n\n\n\u003Cul\u003E\n\u003Cli\u003E\u003Cp\u003E\u003Cstrong\u003EMedian Filter:\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003EDescription:\u003C\u002Fstrong\u003E Use a \u003Ccode\u003Enxn\u003C\u002Fcode\u003E kernel (where \u003Ccode\u003En\u003C\u002Fcode\u003E is a non-zero integer) and slides through image. While sliding, it takes the median value of the pixel values within the kernel and assigns that value to those pixels. This method &quot;smoothens&quot; the image out, and the larger the kernel size, the smoother the image.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Cp\u003E\u003Cstrong\u003EHistogram Equalization:\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003EDescription:\u003C\u002Fstrong\u003E Plot the frequency of each pixel value (with a histogram) and equalizes those frequencies. This histogram plotting and equalization occurs channel-by-channel basis. In terms of channels, the histogram equalization is applied in the YCbCR color space(Luminance, Chroma Blue, Chroma Red).\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003E\u003Cstrong\u003ENote:\u003C\u002Fstrong\u003E Both correction methods can have an optimized runtime of &lt;10-20ms, which makes them suitable for real-time corrections.\u003C\u002Fp\u003E\n\u003Ch2 id=\"results\"\u003EResults\u003C\u002Fh2\u003E\n\u003Cp\u003EThe following are graphs showing the decreasing shape of mAP as a given noise&#39;s intensity rises.\u003C\u002Fp\u003E\n\u003Ch3 id=\"gaussian-blur\"\u003EGaussian Blur\u003C\u002Fh3\u003E\n\u003Cfigure\u003E\n\u003Cimg src=\"post-res\u002Feureca_face\u002Foverview_gaussian_noise_graph.png\" width=\"800\" alt=\"mAP Graph of Gaussian Blur on all models\"\u002F\u003E\n\u003C\u002Ffigure\u003E\n\n\u003Ch3 id=\"salt--pepper\"\u003ESalt &amp; Pepper\u003C\u002Fh3\u003E\n\u003Cfigure\u003E\n\u003Cimg src=\"post-res\u002Feureca_face\u002Foverview_salt_pepper_graph.png\" width=\"800\" alt=\"mAP Graph of Salt & Pepper on all models\"\u002F\u003E\n\u003C\u002Ffigure\u003E\n\n\u003Ch3 id=\"poisson\"\u003EPoisson\u003C\u002Fh3\u003E\n\u003Cfigure\u003E\n\u003Cimg src=\"post-res\u002Feureca_face\u002Foverview_poisson_graph.png\" width=\"800\" alt=\"mAP Graph of Poisson on all models\"\u002F\u003E\n\u003C\u002Ffigure\u003E\n\n\u003Ch3 id=\"gamma\"\u003EGamma\u003C\u002Fh3\u003E\n\u003Cfigure\u003E\n\u003Cimg src=\"post-res\u002Feureca_face\u002Foverview_gamma_graph.png\" width=\"800\" alt=\"mAP Graph of Gamma on all models\"\u002F\u003E\n\u003C\u002Ffigure\u003E\n\n\u003Cp\u003EThe following are graphs representing the trend of recovery for each noise intensity of a given noise at a certain level of a correction. Median filter was applied to Salt &amp; Pepper, Gaussian Blur, and Poisson while Histogram Equalization was applied to Gamma alone.\u003C\u002Fp\u003E\n\u003Ch3 id=\"retinaface\"\u003ERetinaface\u003C\u002Fh3\u003E\n\u003Cfigure\u003E\n\u003Cimg src=\"post-res\u002Feureca_face\u002Foverview_median_gaussian_noise_retinaface.png\" width=\"800\" alt=\"Graph showing correction improvements of gaussian noise with median filter\"\u002F\u003E\n\u003C\u002Ffigure\u003E\n\n\u003Cfigure\u003E\n\u003Cimg src=\"post-res\u002Feureca_face\u002Foverview_median_poisson_retinaface.png\" width=\"800\" alt=\"Graph showing correction improvements of poisson noise with median filter\"\u002F\u003E\n\u003C\u002Ffigure\u003E\n\n\u003Cfigure\u003E\n\u003Cimg src=\"post-res\u002Feureca_face\u002Foverview_median_salt_pepper_retinaface.png\" width=\"800\" alt=\"Graph showing correction improvements of salt & pepper with median filter\"\u002F\u003E\n\u003C\u002Ffigure\u003E\n\n\u003Cfigure\u003E\n\u003Cimg src=\"post-res\u002Feureca_face\u002Foverview_he_gamma_retinaface.png\" width=\"800\" alt=\"Graph showing correction improvements of gamma with histogram equalization\"\u002F\u003E\n\u003C\u002Ffigure\u003E\n\n\u003Ch3 id=\"dsfd\"\u003EDSFD\u003C\u002Fh3\u003E\n\u003Cfigure\u003E\n\u003Cimg src=\"post-res\u002Feureca_face\u002Foverview_median_gaussian_noise_dsfd.png\" width=\"800\" alt=\"Graph showing correction improvements of gaussian noise with median filter\"\u002F\u003E\n\u003C\u002Ffigure\u003E\n\n\u003Cfigure\u003E\n\u003Cimg src=\"post-res\u002Feureca_face\u002Foverview_median_poisson_dsfd.png\" width=\"800\" alt=\"Graph showing correction improvements of poisson noise with median filter\"\u002F\u003E\n\u003C\u002Ffigure\u003E\n\n\u003Cfigure\u003E\n\u003Cimg src=\"post-res\u002Feureca_face\u002Foverview_median_salt_pepper_dsfd.png\" width=\"800\" alt=\"Graph showing correction improvements of salt & pepper with median filter\"\u002F\u003E\n\u003C\u002Ffigure\u003E\n\n\u003Cfigure\u003E\n\u003Cimg src=\"post-res\u002Feureca_face\u002Foverview_he_gamma_dsfd.png\" width=\"800\" alt=\"Graph showing correction improvements of gamma with histogram equalization\"\u002F\u003E\n\u003C\u002Ffigure\u003E\n\n\u003Ch3 id=\"tinaface\"\u003ETinaface\u003C\u002Fh3\u003E\n\u003Cp\u003E\u003Ccode\u003EIncomplete\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\n\u003Ch2 id=\"conclusions\"\u003EConclusions\u003C\u002Fh2\u003E\n\u003Cp\u003EThis project shows the degradation behavior that noises such as Gaussian Blur and Salt &amp; Pepper have on highly-accurate face detectors. Salt &amp; Pepper had an accuracy decrease &quot;shape&quot; resembling an inverted S-curve. I believe this is mainly due to the fact that sharp pixel-wise color changes, such as completely black or white, can have drastic effects on the feature extraction from the first set of convolution layers, which can have a cascading effect later on in the network.\u003C\u002Fp\u003E\n\u003Cp\u003EFor a similar reason, this is why you see tamer accuracy decrease &quot;shapes&quot; for Poisson and Gamma (although the later half of Gamma had a drastic decrease -- this is because at a certain point the white-washing had removed enough features to the point where the image is basically white to us).\u003C\u002Fp\u003E\n\u003Cp\u003EGaussian noise had a neutral accuracy decrease &quot;shape&quot;. I believe the reason for this is because the noise is colored and the distribution of colors at most noise levels are not large enough to drastically affect the original pixel color. Only at higher noise intensities do the values become significant enough for the original color values to significantly shift from their original &quot;domain&quot; of color. With this significant shift, an object&#39;s features will be unrecognizable. \u003C\u002Fp\u003E\n\u003Cfigure\u003E\n\u003Cimg src=\"post-res\u002Feureca_face\u002Fmedian_fix_demo.png\" width=\"800\" alt=\"Example of median filter recovering detections from a image at a higher salt & pepper intensity\"\u002F\u003E\n\u003C\u002Ffigure\u003E\n\n\u003Cfigure\u003E\n\u003Cimg src=\"post-res\u002Feureca_face\u002Fhe_fix_demo.png\" width=\"800\" alt=\"Example of histogram equalization recovering a moderate amount of faces from a very white-washed image\"\u002F\u003E\n\u003C\u002Ffigure\u003E\n\n\u003Cp\u003E\u003Cstrong\u003EThe source code and documentation on how to set up this project is located \u003Ca target=\"_blank\" rel=\"nofollow\" href=\"https:\u002F\u002Fgithub.com\u002Fvjsrinivas\u002Feureca_face\"\u003Ehere\u003C\u002Fa\u003E\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\n",created:"Fri, 14 May 2021 12:15:49 GMT",excerpt:"This project was done to complete one of my breadth requirements for the Tickle Engineering Honors program. The contents of the project were presented at the 2021 EUReCA Symposium as a poster. To keep proper context, the project was completed within less than a month and is a continuation of adjacent, prior works regarding image degradation and Convolutional Neural Networks.\n",author:a,readingTime:"7 min read",mediaFilePath:"post-res\u002Feureca_face\u002Feureca_face_thumb.png",tags:["machine learning"],art_credit:a}}}("Vijay Rajagopal"))]};if('serviceWorker' in navigator)navigator.serviceWorker.register('/service-worker.js');var s=document.createElement("script");try{new Function("if(0)import('')")();s.src="/client/client.4da8ec3a.js";s.type="module";s.crossOrigin="use-credentials";}catch(e){s.src="/client/shimport@1.0.1.js";s.setAttribute("data-main","/client/client.4da8ec3a.js")}document.head.appendChild(s)</script> 